# ACE (Anti-Chaos Engine) User Guide

## Overview

ACE is a powerful tool designed to ensure and maintain consistency across nodes in a pgEdge cluster. It helps identify and resolve data inconsistencies, schema differences, and replication configuration mismatches across nodes in a cluster.

Key features include:
- Table-level data comparison and repair
- Replication set level verification
- Automated repair capabilities
- Schema comparison
- Spock configuration validation

## Table Diff Module

The table-diff module compares table data across nodes in a cluster to identify inconsistencies.

### Usage

```bash
./pgedge ace table-diff <cluster_name> <schema.table_name> [options]
```

#### Required Arguments

- `cluster_name`: Name of the cluster as defined in your configuration
- `schema.table_name`: Fully qualified table name (e.g., "public.users")

#### Optional Arguments

- `--dbname`: Database name (defaults to first database in cluster config)
- `--block-rows`: Number of rows to process per block (default: 10000)
  - Min: 1000
  - Max: 100000
  - Higher values improve performance but increase memory usage
  - This is a configurable parameter in ace_config.py
- `--max-cpu-ratio`: Maximum CPU utilisation (0.0-1.0, default: 0.6)
  - Configurable in ace_config.py
- `--output`: Output format ["json", "csv", "html"] (default: "json")
- `--nodes`: Specific nodes to compare ("all" or comma-separated list, default: "all")
- `--batch-size`: Number of blocks to process per multiprocessing worker (default: 1)
  - The higher the number, the lower the parallelism
  - Configurable in ace_config.py
- `--quiet`: Suppress non-essential output
- `--table-filter`: SQL WHERE clause to filter rows for comparison
  - Can be used to compare specific blocks of data. Useful for large tables.

#### Examples

Basic comparison of a table across all nodes:
```bash
./pgedge ace table-diff my_cluster public.customers
```

Compare specific nodes with custom block size:
```bash
./pgedge ace table-diff my_cluster public.orders --nodes="node1,node2" --block-rows=50000
```

Generate HTML report with filtered data:
```bash
./pgedge ace table-diff my_cluster public.transactions \
  --output=html \
  --table-filter="created_at > '2024-01-01'"
```

### Output

The tool generates a report containing:
- Summary of compared rows
- Mismatched data details
- Node-specific statistics
- Error logs (if any)

For HTML output, an interactive report is generated with:
- Colour-coded differences
- Expandable row details
- Primary key highlighting
- Missing row indicators

### Common Use Cases

1. **Regular Verification**:
   ```bash
   ./pgedge ace table-diff my_cluster public.critical_data --output=html
   ```

2. **Performance-Optimised Large Table Scan**:
   ```bash
   ./pgedge ace table-diff my_cluster public.large_table \
     --block-rows=50000 \
     --max-cpu-ratio=0.6 \
     --batch-size=30
   ```

3. **Focused Comparison**:
   ```bash
   ./pgedge ace table-diff my_cluster public.orders \
     --nodes="primary,replica1" \
     --table-filter="order_date >= CURRENT_DATE - INTERVAL '7 days'"
   ```

### Best Practices

1. Experiment with different block sizes and CPU utilisation to find the best performance/resource-usage balance for your workload
2. Use `--table-filter` for large tables to reduce comparison scope
3. Generate HTML reports for easier analysis of differences
4. Ensure the diffs have not overrun the MAX_ALLOWED_DIFFS limit--otherwise, table-repair will only be able to partially repair the table.

## Table Repair Module

The table-repair module fixes data inconsistencies identified by the table-diff module. It uses a specified node as the source of truth to correct data on other nodes.

In some special cases, you may want to use the `--fix-nulls` option to fix NULL values by comparing across nodes. E.g., if there was an issue where a column was not being replicated, you can use this option to fix the NULL values on the target nodes. This does not need a source of truth node as it consults the diff file to determine which rows have NULL values. However, it is for this special case only, and should not be used for other types of data inconsistencies.

### Usage

```bash
./pgedge ace table-repair <cluster_name> <schema.table_name> --diff-file=<diff_file> --source-of-truth=<source_of_truth> [options]
```

### Required Arguments

- `cluster_name`: Name of the cluster as defined in your configuration
- `diff_file`: Path to the JSON diff file generated by table-diff
- `source_of_truth`: Node name to use as the source of truth for repairs
- `schema.table_name`: Fully qualified table name (e.g., "public.users")

### Optional Arguments

- `--dbname`: Database name (defaults to first database in cluster config)
- `--dry-run`: Simulate repair operations without making changes (default: false)
- `--quiet`: Suppress non-essential output
- `--generate-report`: Create a detailed report of repair operations
- `--upsert-only`: Only perform inserts/updates, skip deletions
- `--fix-nulls`: Fix NULL values by comparing across nodes (special use case)

### Examples

Basic repair using a diff file:
```bash
./pgedge ace table-repair my_cluster /path/to/diff.json primary public.customers
```

Dry run with report generation:
```bash
./pgedge ace table-repair my_cluster /path/to/diff.json primary public.orders \
  --dry-run=True \
  --generate-report=True
```

Conservative repair (updates only):
```bash
./pgedge ace table-repair my_cluster public.transactions \
  --diff-file=/path/to/diff.json \
  --source-of-truth=primary \
  --upsert-only=True
```

### Safety Features

1. **Dry Run Mode**: Test repairs without making changes
2. **Upsert-Only Option**: Prevent data deletion
3. **Transaction Safety**: All changes are atomic
4. **Logging**: Detailed repair audit trail
5. **Validation**: Pre-repair consistency checks

### Best Practices

1. Ensure MAX_ALLOWED_DIFFS have not exceeded during table-diff. Otherwise, table-repair will only be able to partially repair the table.
2. Run with `--dry-run` first to review proposed changes
3. Use `--upsert-only` for critical tables where data deletion may be risky
4. Verify table structure and constraints before repair

### Common Use Cases

1. **Post-Migration Verification**:
   ```bash
   ./pgedge ace table-repair my_cluster public.users \
     --diff-file=migration_diff.json \
     --source-of-truth=source_db \
     --generate-report=True
   ```

2. **Safe Production Repair**:
   ```bash
   ./pgedge ace table-repair my_cluster public.orders \
     --diff-file=prod_diff.json \
     --source-of-truth=primary \
     --upsert-only \
     --generate-report=True
   ```

3. **Maintenance Window Repair**:
   ```bash
   ./pgedge ace table-repair my_cluster weekly_diff.json primary public.inventory \
     --generate-report=True
   ```

## Table Rerun Module

The table-rerun module allows you to rerun a previous table diff operation using an existing diff file. This is useful for verifying fixes or checking if inconsistencies persist after repairs.

### Usage

```bash
./pgedge ace table-rerun <cluster_name> <schema.table_name> --diff-file=<diff_file> [options]
```

### Required Arguments

- `cluster_name`: Name of the cluster as defined in your configuration
- `schema.table_name`: Fully qualified table name (e.g., "public.users")
- `diff_file`: Path to the JSON diff file from a previous table-diff operation

### Optional Arguments

- `--dbname`: Database name (defaults to first database in cluster config)
- `--quiet`: Suppress non-essential output
- `--behavior`: Processing behavior ["multiprocessing", "hostdb"] (default: "multiprocessing")
  - `multiprocessing`: Uses parallel processing for faster execution
  - `hostdb`: Uses the host database to create temporary tables for faster comparisons (useful for very large tables and diffs)

### Examples

Basic rerun of a previous diff:
```bash
./pgedge ace table-rerun my_cluster public.customers \
  --diff-file=/path/to/diff.json
```

Rerun with host database comparison:
```bash
./pgedge ace table-rerun my_cluster public.orders \
  --diff-file=/path/to/diff.json \
  --behavior=hostdb
```

### Use Cases

1. Post-Repair Verification: Check if the table-repair run has resolved the diffs identified previously.
2. Veryfing if diffs identified by table-diff still exist after the replication lag window has elapsed.

### Best Practices

1. Use `hostdb` behavior for very large tables and diffs to improve performance
2. Compare results with the original diff file to check if some differences were resolved after a replication lag window.

## API Reference

ACE provides a REST API for programmatic access. The API server runs on localhost:5000 by default. An SSH tunnel is required to access the API from outside the host machine for security purposes.

### Table Diff API

Initiates a table diff operation.

**Endpoint:** `GET /ace/table-diff`

**Parameters:**
- `cluster_name` (required): Name of the cluster
- `table_name` (required): Fully qualified table name (schema.table)
- `dbname` (optional): Database name
- `block_rows` (optional): Number of rows per block (default: 10000)
- `max_cpu_ratio` (optional): Maximum CPU usage ratio (default: 0.8)
- `output` (optional): Output format ["json", "csv", "html"] (default: "json")
- `nodes` (optional): Nodes to include ("all" or comma-separated list)
- `batch_size` (optional): Batch size for processing (default: 50)
- `table_filter` (optional): SQL WHERE clause to filter rows for comparison
- `quiet` (optional): Suppress output (default: false)

**Example Request:**
```bash
curl "http://localhost:5000/ace/table-diff?cluster_name=my_cluster&table_name=public.users&output=html"
```

**Example Response:**
```json
{
    "task_id": "td_20240315_123456",
    "submitted_at": "2024-03-15T12:34:56.789Z"
}
```

### Table Repair API

Initiates a table repair operation.

**Endpoint:** `GET /ace/table-repair`

**Parameters:**
- `cluster_name` (required): Name of the cluster
- `diff_file` (required): Path to the diff file
- `source_of_truth` (required): Source node for repairs
- `table_name` (required): Fully qualified table name
- `dbname` (optional): Database name
- `dry_run` (optional): Simulate repairs (default: false)
- `quiet` (optional): Suppress output (default: false)
- `generate_report` (optional): Create detailed report (default: false)
- `upsert_only` (optional): Skip deletions (default: false)

**Example Request:**
```bash
curl "http://localhost:5000/ace/table-repair?cluster_name=my_cluster&diff_file=/path/to/diff.json&source_of_truth=primary&table_name=public.users"
```

**Example Response:**
```json
{
    "task_id": "tr_20240315_123456",
    "submitted_at": "2024-03-15T12:34:56.789Z"
}
```

### Table Rerun API

Reruns a previous table diff operation.

**Endpoint:** `GET /ace/table-rerun`

**Parameters:**
- `cluster_name` (required): Name of the cluster
- `diff_file` (required): Path to the previous diff file
- `table_name` (required): Fully qualified table name
- `dbname` (optional): Database name
- `quiet` (optional): Suppress output (default: false)
- `behavior` (optional): Processing behavior ["multiprocessing", "hostdb"]

**Example Request:**
```bash
curl "http://localhost:5000/ace/table-rerun?cluster_name=my_cluster&diff_file=/path/to/diff.json&table_name=public.users"
```

**Example Response:**
```json
{
    "task_id": "tr_20240315_123456",
    "submitted_at": "2024-03-15T12:34:56.789Z"
}
```

### Task Status API

Retrieves the status of a submitted task.

**Endpoint:** `GET /ace/task-status/<task_id>`

**Example Request:**
```bash
curl "http://localhost:5000/ace/task-status/td_20240315_123456"
```

**Example Response:**
```json
{
    "task_id": "td_20240315_123456",
    "task_type": "table-diff",
    "status": "COMPLETED",
    "started_at": "2024-03-15T12:34:56.789Z",
    "finished_at": "2024-03-15T12:35:01.234Z",
    "time_taken": 4.445,
    "result": {
        "diff_file": "/path/to/output.json",
        "total_rows": 10000,
        "mismatched_rows": 5
        "summary": {

        }
    }
}
```

### Error Responses

All API endpoints return error responses in the following format:

```json
{
    "error": "Description of what went wrong"
}
```

Common HTTP status codes:
- 200: Success
- 400: Bad Request (missing or invalid parameters)
- 404: Not Found (invalid cluster or task ID)
- 500: Internal Server Error

## Scheduled Operations (Beta)

ACE supports automated scheduling of table-diff operations through configuration settings in `ace_config.py`. This allows for regular consistency checks without manual intervention.

### Configuration

In `ace_config.py`, you define jobs and their schedules in two separate lists:

```python
# Define the jobs
schedule_jobs = [
    {
        "name": "t1",
        "cluster_name": "my_cluster",
        "table_name": "public.users"
    },
    {
        "name": "t2",
        "cluster_name": "my_cluster",
        "table_name": "public.orders",
        "args": {
            "max_cpu_ratio": 0.7,
            "batch_size": 1000,
            "block_rows": 10000,
            "nodes": "all",
            "output": "json",
            "quiet": False,
            "dbname": "mydb"
        }
    }
]

# Define the schedule for each job
schedule_config = [
    {
        "job_name": "t1",
        "crontab_schedule": "0 0 * * *",    # Run at midnight
        "run_frequency": "30s",             # Alternative to crontab
        "enabled": True,
        "rerun_after": "1h"                # Rerun if diff found after 1 hour
    },
    {
        "job_name": "t2",
        "crontab_schedule": "0 */4 * * *",  # Every 4 hours
        "run_frequency": "5m",              # Alternative to crontab
        "enabled": True,
        "rerun_after": "30m"
    }
]
```

### Job Configuration Options

Each job in `schedule_jobs` supports:

- `name` (required): Unique identifier for the job
- `cluster_name` (required): Name of the cluster
- `table_name` (required): Fully qualified table name
- `args` (optional): Dictionary of table-diff parameters
  - `max_cpu_ratio`: Maximum CPU usage ratio
  - `batch_size`: Batch size for processing
  - `block_rows`: Number of rows per block
  - `table_filter`: SQL WHERE clause to filter rows for comparison
  - `nodes`: Nodes to include
  - `output`: Output format ["json", "csv", "html"]
  - `quiet`: Suppress output
  - `dbname`: Database name

### Schedule Configuration Options

Each schedule in `schedule_config` supports:

- `job_name` (required): Name of the job to schedule (must match a job name)
- `crontab_schedule`: Cron-style schedule expression
- `run_frequency`: Alternative to crontab, using time units (e.g., "30s", "5m", "1h")
- `enabled`: Whether the schedule is active (default: False)
<!-- - `rerun_after`: Time to wait before rerunning if differences found -->

### Time Formats

- **Cron Format**: `* * * * *` (minute hour day_of_month month day_of_week)
  - Examples:
    - `0 0 * * *`: Daily at midnight
    - `0 */4 * * *`: Every 4 hours
    - `0 0 * * 0`: Weekly on Sunday

- **Run Frequency Format**: `<number><unit>`
  - Units: "s" (seconds), "m" (minutes), "h" (hours)
  - Minimum: 5 minutes
  - Examples:
    - "30s": Every 30 seconds
    - "5m": Every 5 minutes
    - "1h": Every hour


### Starting and Stopping the Scheduler

The scheduler starts automatically when ACE is started.

```bash
./pgedge start ace
```

To stop the scheduler:

```bash
./pgedge stop ace
```

### Best Practices

1. **Resource Management**: 
   - Stagger schedules to avoid overlapping resource-intensive jobs
   - Set appropriate `max_cpu_ratio`, `block_rows`, and `batch_size` values based on the
     table size and expected load
2. **Frequency Selection**:
   - Use `crontab_schedule` for specific times
   - Use `run_frequency` for regular intervals

## Auto-Repair Module (Beta)

The auto-repair module automatically monitors and repairs data inconsistencies in your cluster. It runs as a background process, periodically checking for inconsistencies and applying repairs based on configured settings.

### Configuration

Auto-repair settings are defined in `ace_config.py`:

```python
auto_repair_config = {
    "enabled": True,
    "cluster_name": "my_cluster",
    "dbname": "mydb",
    "poll_interval": "1000s",
    "status_update_interval": "1000s"
}
```

### Configuration Options

- `enabled`: Enable/disable auto-repair functionality (default: False)
- `cluster_name`: Name of the cluster to monitor
- `dbname`: Database name to monitor
- `poll_interval`: How often the Spock exception log is polled to check for new exceptions.
- `status_update_interval`: How often the Spock exception status and detail tables are updated with the latest exception status.

### Time Intervals

Both `poll_interval` and `status_update_interval` accept time strings in the format:
- `<number>s`: Seconds (e.g., "60s")
- `<number>m`: Minutes (e.g., "5m")
- `<number>h`: Hours (e.g., "1h")

### Usage

The auto-repair daemon starts automatically when ACE is started.

```bash
./pgedge start ace
```

To stop the auto-repair daemon:

```bash
./pgedge stop ace
```

### Common Use Cases

Auto-repair is a great candidate for handling use-cases that have a high probability of insert-insert conflicts.
E.g., bidding, reservations, etc., where insert-insert conflicts are likely to arise across multiple nodes.


### Limitations and Considerations
- The auto-repair daemon is currently limited to handling insert-insert conflicts only.
- Handling other types of conflicts is planned for future releases.